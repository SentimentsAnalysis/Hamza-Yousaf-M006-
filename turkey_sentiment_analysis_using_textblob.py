# -*- coding: utf-8 -*-
"""Turkey sentiment analysis using TextBlob.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MsRcwsxG9ay6DN4kCN_EqAf9tOVgiFfB
"""

#import libraries

from textblob import TextBlob
import pandas as pd
import matplotlib.pyplot as plt

pip install neattext

#read data set 
turkey = pd.read_csv('turkey.csv', encoding = 'ISO-8859-1')

#display first 5 rows of the data set
turkey.head()

#display last 5 rows of the data set
turkey.tail()

#rows and clm
turkey.shape

#information about the data set
turkey.info()

#calculate null values in the data set
turkey.isnull().sum()

#drop the null values
turkey = turkey.dropna()

#after deleting again check the null values
turkey.isnull().sum()

#after the deletion of null values again check the shape of the data set
turkey.shape

#import cleaning package
import neattext.functions as nfx

#show total packages in neattext pacakge
dir(nfx)

#showing tweet before cleaning (all tweets)
turkey['Tweet']

#specific tweet (before cleaning)
turkey['Tweet'].iloc[2]

#extract hashtags from tweet column
turkey['Tweet'].apply(nfx.extract_hashtags)

#store extracted hashtags in new column called "extracted hashtags"
turkey['extracted_hashtags']=turkey['Tweet'].apply(nfx.extract_hashtags)

#compare extracted hashtags with tweets(before cleaning)
turkey[['extracted_hashtags','Tweet']]

#matching of extracted hashtags with specific tweet (before cleaning)
turkey['Tweet'].iloc[0]

#cleaning of hashtags

turkey['clean_tweet']=turkey['Tweet'].apply(nfx.remove_hashtags)

#comparison with old Tweet and cleaned Tweet (HASHTAGS)
turkey[['Tweet','clean_tweet']]

#after cleaning hashtags display clean tweet
turkey['clean_tweet']

# first 5 reows 
turkey.head()

#cleaning extra spaces

#before

turkey['clean_tweet'].iloc[2]

turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_multiple_spaces)

#after cleaning
turkey['clean_tweet'].iloc[2]

#cleaning urls
turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_urls)

#after cleaning
turkey['clean_tweet'].iloc[2]

#cleaning punctuation
turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_puncts)

#cleaning stop words
turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_stopwords)

#remove special character
turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_special_characters)

#final

turkey[['Tweet','clean_tweet']]

#define function for subjectivity
def getTextSubjectivity(txt):
  return TextBlob(txt).sentiment.subjectivity

#define function for polarity
def getTextPolarity(txt):
  return TextBlob(txt).sentiment.polarity

#apply both functions subjectivity and polarity to clean tweet
turkey['Subjectivity']=turkey['clean_tweet'].apply(getTextSubjectivity)
turkey['Polarity']=turkey['clean_tweet'].apply(getTextPolarity)

turkey.head(5)

#define function for polarity calculation
def getTextAnalysis(a):
  if a<0:
    return "depressed"
  elif a==0:
    return "neutral"
  else:
    return "happy"

turkey['sentiment']=turkey['Polarity'].apply(getTextAnalysis)

turkey.head(5)

#calculating percentage of happy tweets 
happy=turkey[turkey['sentiment']=="happy"]
print(str(happy.shape[0]/(turkey.shape[0])*100)+" % Happy Tweets")
Happy=happy.shape[0]/turkey.shape[0]*100

#calculating percentage of neutral tweets
neutral=turkey[turkey['sentiment']=="neutral"]
print(str(neutral.shape[0]/(turkey.shape[0])*100)+" % Neutral Tweets")
Neutral=neutral.shape[0]/turkey.shape[0]*100

#calculating percentage of Depressed tweets 
depressed=turkey[turkey['sentiment']=="depressed"]
print(str(depressed.shape[0]/(turkey.shape[0])*100)+" % Depressed Tweets")
Depressed=depressed.shape[0]/turkey.shape[0]*100

# Pie chart

labels = ['Happy', 'Neutral', 'Depressed']
sizes = [Happy, Neutral, Depressed]
colors = ['#ff9999','#66b3ff','#99ff99']
explode = (0.1, 0, 0)  # only "explode" the 1st slice (Happy)

fig1, ax1 = plt.subplots(figsize=(10, 10))
ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', 
        shadow=True, startangle=0)
ax1.axis('equal')
plt.xlabel("Sentiments")

plt.title("Sentiment Analysis on Turkey Earthquake", fontweight='bold')
plt.legend(title='Sentiment', labels=labels, loc="upper left", bbox_to_anchor=(1,1), fontsize=12)
plt.show()

#bar chart

labels = turkey.groupby('sentiment').count().index.values #(how many values fall in happy cateogery)
values = turkey.groupby('sentiment').size().values #sizes(happy,depressed,neutral)
plt.bar(labels,values)

#scatter plot

for index, row in turkey.iterrows():
  if row['sentiment']=='happy':
    plt.scatter(row['Polarity'],row['Subjectivity'],color='green')
  elif row['sentiment']=='depressed':
    plt.scatter(row['Polarity'],row['Subjectivity'],color='red')
  elif row['sentiment']=='neutral':
    plt.scatter(row['Polarity'],row['Subjectivity'],color='blue')

  plt.title('Twitter Sentiment Analysis')
  plt.xlabel('Polarity')
  plt.ylabel('Subjectivity')

#performance evaluation
from sklearn.model_selection import train_test_split

train_data, test_data = train_test_split(turkey, test_size=0.3, random_state=42)

test_data['predicted'] = test_data['clean_tweet'].apply(getTextAnalysis)

from sklearn.metrics import accuracy_score
score = accuracy_score(test_data['sentiment'], test_data['predicted'])
print("Accuracy: ", score)

