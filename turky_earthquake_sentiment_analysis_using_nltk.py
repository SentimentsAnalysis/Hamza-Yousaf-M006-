# -*- coding: utf-8 -*-
"""Turky_Earthquake sentiment analysis using NLTK

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gPDitZXRxxTjCwKWq2BaU-A9utnEMOfG
"""

#import libraries

from textblob import TextBlob
import pandas as pd
import matplotlib.pyplot as plt

pip install neattext

#import data set
from google.colab import files
upload = files.upload()

#read data set 
turkey = pd.read_csv('turkey.csv', encoding = 'ISO-8859-1')

#display first 5 rows of the data set
turkey.head()

#display last 5 rows of the data set
turkey.tail()

#rows and clm
turkey.shape

#information about the data set
turkey.info()

#calculate null values in the data set
turkey.isnull().sum()

#drop the null values
turkey = turkey.dropna()

#after deleting again check the null values
turkey.isnull().sum()

#after the deletion of null values again check the shape of the data set
turkey.shape

#import cleaning package
import neattext.functions as nfx

#show total packages in neattext pacakge
dir(nfx)

#showing tweet before cleaning (all tweets)
turkey['Tweet']

#specific tweet (before cleaning)
turkey['Tweet'].iloc[2]

#extract hashtags from tweet column
turkey['Tweet'].apply(nfx.extract_hashtags)

#store extracted hashtags in new column called "extracted hashtags"
turkey['extracted_hashtags']=turkey['Tweet'].apply(nfx.extract_hashtags)

#compare extracted hashtags with tweets(before cleaning)
turkey[['extracted_hashtags','Tweet']]

#matching of extracted hashtags with specific tweet (before cleaning)
turkey['Tweet'].iloc[0]

#cleaning of hashtags

turkey['clean_tweet']=turkey['Tweet'].apply(nfx.remove_hashtags)

#comparison with old Tweet and cleaned Tweet (HASHTAGS)
turkey[['Tweet','clean_tweet']]

#after cleaning hashtags display clean tweet
turkey['clean_tweet']

# first 5 reows 
turkey.head()

#cleaning extra spaces

#before

turkey['clean_tweet'].iloc[2]

turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_multiple_spaces)

#after cleaning
turkey['clean_tweet'].iloc[2]

#cleaning urls
turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_urls)

#after cleaning
turkey['clean_tweet'].iloc[2]

#cleaning punctuation
turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_puncts)

#cleaning stop words
turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_stopwords)

#remove special character
turkey['clean_tweet'] = turkey['clean_tweet'].apply(nfx.remove_special_characters)

#final

turkey[['Tweet','clean_tweet']]

#define function for subjectivity
#def getTextSubjectivity(txt):
  #return TextBlob(txt).sentiment.subjectivity

#define function for polarity
#def getTextPolarity(txt):
  #return TextBlob(txt).sentiment.polarity

#apply both functions subjectivity and polarity to clean tweet
#flood['Subjectivity_t']=flood['clean_tweet'].apply(getTextSubjectivity)
#flood['Polarity_t']=flood['clean_tweet'].apply(getTextPolarity)

turkey.head(5)

#define function for polarity calculation
#def getTextAnalysis(a):
  #if a<0:
    #return "Depressed"
  #elif a==0:
    #return "Neutral"
  #else:
    #return "Happy"

#import python library Natural Language Toolkit
import nltk

#download nltk library Valence Aware Dictionary and sEntiment Reasoner
nltk.download('vader_lexicon')

#import sentimentIntensityAnalyzer from vader (pre-defined)
from nltk.sentiment.vader import SentimentIntensityAnalyzer

#create function for getting sentiment from each tweet
def get_emotion(text):
    sid = SentimentIntensityAnalyzer() #create instance for sentimentintensityanalyzer (pretrained that uses vader)
    score = sid.polarity_scores(text)  #calculate polarity for each tweet and store these values in compound (pos,neg,neu)
    if score['compound'] >= 0.5:
        return 'joyful'
    elif score['compound'] > 0:
        return 'happy'
    elif score['compound'] == 0:
        return 'neutral'
    elif score['compound'] > -0.5:
        return 'sad'
    else:
        return 'angry'

#apply the function on clean_tweet
turkey['Score1'] = turkey['clean_tweet'].apply(get_emotion)

turkey.head(5)

turkey.tail(5)

#calculating percentage of happy tweets 
happy=turkey[turkey['Score1']=="happy"]
print(str(happy.shape[0]/(turkey.shape[0])*100)+" % Happy Tweets")
Happy=happy.shape[0]/turkey.shape[0]*100

#calculating percentage of angry tweets
angry=turkey[turkey['Score1']=="angry"]
print(str(angry.shape[0]/(turkey.shape[0])*100)+" % Angry Tweets")
Angry=angry.shape[0]/turkey.shape[0]*100

#calculating percentage of sad tweets
sad=turkey[turkey['Score1']=="sad"]
print(str(sad.shape[0]/(turkey.shape[0])*100)+" % Sad Tweets")
Sad=sad.shape[0]/turkey.shape[0]*100

#calculating percentage of joyful tweets
joyful=turkey[turkey['Score1']=="joyful"]
print(str(joyful.shape[0]/(turkey.shape[0])*100)+" % Joyful Tweets")
Joyful=joyful.shape[0]/turkey.shape[0]*100

#calculating percentage of neutral tweets
neutral=turkey[turkey['Score1']=="neutral"]
print(str(neutral.shape[0]/(turkey.shape[0])*100)+" % Neutral Tweets")
Neutral=neutral.shape[0]/turkey.shape[0]*100

# Pie chart

labels = ['Angry', 'Neutral', 'Happy', 'Sad', 'Joyful']
sizes = [Angry, Neutral, Happy, Sad, Joyful]
colors = ['#ff9999','#66b3ff','#99ff99','#ffcccc','#99ff99']
explode = (0, 0, 0.1, 0, 0)  # only "explode" the 3rd slice (Happy)

fig1, ax1 = plt.subplots(figsize=(10, 10))
ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', 
        shadow=True, startangle=0)
ax1.axis('equal')
plt.xlabel("Sentiments")
#plt.ylabel("Percentage")
plt.title("Sentiment Analysis on Turkey Earthquake", fontweight='bold')
plt.legend(title='Sentiment', labels=labels, loc="upper left", bbox_to_anchor=(1,1), fontsize=12)
plt.show()

# % is a special character that indicates the start of a format specification.
#1.1 specifies the precision of the value (1 digit before the decimal point and 1 digit after the decimal point)
#f specifies that the value should be formatted as a floating-point number
#%% is used to represent a literal % character

#bar chart

labels = turkey.groupby('Score1').count().index.values #(how many values fall in happy cateogery)
values = turkey.groupby('Score1').size().values #sizes(happy,depressed,neutral)
plt.bar(labels,values)

#scatter plot

for index, row in turkey.iterrows():
  if row['Score']=='Happy':
    plt.scatter(row['Polarity'],row['Subjectivity'],color='green')
  elif row['Score']=='Depressed':
    plt.scatter(row['Polarity'],row['Subjectivity'],color='red')
  elif row['Score']=='Neutral':
    plt.scatter(row['Polarity'],row['Subjectivity'],color='blue')

  plt.title('Twitter Sentiment Analysis')
  plt.xlabel('Polarity')
  plt.ylabel('Subjectivity')

#performance evaluation
from sklearn.model_selection import train_test_split

train_data, test_data = train_test_split(turkey, test_size=0.3, random_state=42)

test_data['predicted'] = test_data['clean_tweet'].apply(get_emotion)

from sklearn.metrics import accuracy_score
score = accuracy_score(test_data['Score1'], test_data['predicted'])
print("Accuracy: ", score)